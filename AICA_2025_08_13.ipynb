{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU6QSdFv31+w1ILurDdj1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minmings111/AICA_study/blob/main/AICA_2025_08_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I5sa5nCfvUKg"
      },
      "outputs": [],
      "source": [
        "# 2025.08.13. --1\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./data/wine.csv', header = None)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iD8r0N0U3JHx",
        "outputId": "3c6bfa27-b986-46aa-dfc6-2fbd2594d702"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
              "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
              "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
              "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
              "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
              "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
              "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
              "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
              "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
              "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
              "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
              "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
              "\n",
              "      11  12  \n",
              "0      5   1  \n",
              "1      5   1  \n",
              "2      5   1  \n",
              "3      6   1  \n",
              "4      5   1  \n",
              "...   ..  ..  \n",
              "6492   6   0  \n",
              "6493   5   0  \n",
              "6494   6   0  \n",
              "6495   7   0  \n",
              "6496   6   0  \n",
              "\n",
              "[6497 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e47b841-9be3-409c-887c-04164906b3e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.99680</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.99780</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6492</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6493</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6494</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6495</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6496</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6497 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e47b841-9be3-409c-887c-04164906b3e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e47b841-9be3-409c-887c-04164906b3e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e47b841-9be3-409c-887c-04164906b3e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ecfc84d4-58ed-43b0-8a60-17bed057b551\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecfc84d4-58ed-43b0-8a60-17bed057b551')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ecfc84d4-58ed-43b0-8a60-17bed057b551 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0fb7c628-7a79-4845-92e1-e3ab9742a6f4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0fb7c628-7a79-4845-92e1-e3ab9742a6f4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6497,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.296433757799792,\n        \"min\": 3.8,\n        \"max\": 15.9,\n        \"num_unique_values\": 106,\n        \"samples\": [\n          7.15,\n          8.1,\n          7.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1646364740846772,\n        \"min\": 0.08,\n        \"max\": 1.58,\n        \"num_unique_values\": 187,\n        \"samples\": [\n          0.405,\n          0.21,\n          0.695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14531786489759185,\n        \"min\": 0.0,\n        \"max\": 1.66,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.1,\n          0.6,\n          0.37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.757803743147445,\n        \"min\": 0.6,\n        \"max\": 65.8,\n        \"num_unique_values\": 316,\n        \"samples\": [\n          18.95,\n          3.2,\n          9.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03503360137245906,\n        \"min\": 0.009,\n        \"max\": 0.611,\n        \"num_unique_values\": 214,\n        \"samples\": [\n          0.089,\n          0.217,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.74939977200255,\n        \"min\": 1.0,\n        \"max\": 289.0,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          77.5,\n          65.0,\n          128.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56.521854522630264,\n        \"min\": 6.0,\n        \"max\": 440.0,\n        \"num_unique_values\": 276,\n        \"samples\": [\n          14.0,\n          149.0,\n          227.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002998673003719041,\n        \"min\": 0.98711,\n        \"max\": 1.03898,\n        \"num_unique_values\": 998,\n        \"samples\": [\n          0.9918,\n          0.99412,\n          0.99484\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1607872021039883,\n        \"min\": 2.72,\n        \"max\": 4.01,\n        \"num_unique_values\": 108,\n        \"samples\": [\n          3.74,\n          3.17,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14880587361448958,\n        \"min\": 0.22,\n        \"max\": 2.0,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          1.11,\n          1.56,\n          0.46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.192711748870997,\n        \"min\": 8.0,\n        \"max\": 14.9,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          10.9333333333333,\n          9.7,\n          10.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 9,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          5,\n          6,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:12]\n",
        "y = df.iloc[:,12]"
      ],
      "metadata": {
        "id": "B6a6Tdmp3QIo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)"
      ],
      "metadata": {
        "id": "mY5hf-I03s9e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Dense: 은닉층 안의 노드 수. 너무 많으면 과적합, 적으면 학습불가.\n",
        "# 은닉층이 너무 많아도 과적합, 기울기 소실 문제 발생 가능성 있음.\n",
        "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
        "model.add(Dense(12, activation = 'relu'))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "2_Lv9Zl84Mv9",
        "outputId": "5e013eaf-856a-4dfb-fc3d-ab622ef321e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jPDvta8n99TP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 20, batch_size = 500, validation_split = 0.25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZlMHnXX-FqB",
        "outputId": "4071bbb3-4eb4-4609-b653-a70b7677fb2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.2373 - loss: 22.9063 - val_accuracy: 0.2438 - val_loss: 12.6653\n",
            "Epoch 2/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2461 - loss: 9.7218 - val_accuracy: 0.3377 - val_loss: 1.3608\n",
            "Epoch 3/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6015 - loss: 0.8319 - val_accuracy: 0.7585 - val_loss: 0.8513\n",
            "Epoch 4/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7556 - loss: 1.0138 - val_accuracy: 0.7577 - val_loss: 1.0684\n",
            "Epoch 5/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7580 - loss: 1.1448 - val_accuracy: 0.7592 - val_loss: 0.9798\n",
            "Epoch 6/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7531 - loss: 1.0680 - val_accuracy: 0.7923 - val_loss: 0.7683\n",
            "Epoch 7/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8003 - loss: 0.7663 - val_accuracy: 0.8400 - val_loss: 0.5255\n",
            "Epoch 8/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8481 - loss: 0.5304 - val_accuracy: 0.8869 - val_loss: 0.3287\n",
            "Epoch 9/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8784 - loss: 0.3351 - val_accuracy: 0.8969 - val_loss: 0.2654\n",
            "Epoch 10/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8799 - loss: 0.3068 - val_accuracy: 0.8877 - val_loss: 0.2827\n",
            "Epoch 11/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8705 - loss: 0.3066 - val_accuracy: 0.9046 - val_loss: 0.2492\n",
            "Epoch 12/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8927 - loss: 0.2810 - val_accuracy: 0.9085 - val_loss: 0.2409\n",
            "Epoch 13/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9041 - loss: 0.2663 - val_accuracy: 0.9131 - val_loss: 0.2342\n",
            "Epoch 14/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9003 - loss: 0.2653 - val_accuracy: 0.9154 - val_loss: 0.2282\n",
            "Epoch 15/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9040 - loss: 0.2578 - val_accuracy: 0.9185 - val_loss: 0.2236\n",
            "Epoch 16/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9085 - loss: 0.2509 - val_accuracy: 0.9185 - val_loss: 0.2180\n",
            "Epoch 17/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9084 - loss: 0.2430 - val_accuracy: 0.9200 - val_loss: 0.2099\n",
            "Epoch 18/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9103 - loss: 0.2373 - val_accuracy: 0.9269 - val_loss: 0.2011\n",
            "Epoch 19/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9154 - loss: 0.2325 - val_accuracy: 0.9308 - val_loss: 0.1930\n",
            "Epoch 20/20\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9241 - loss: 0.2241 - val_accuracy: 0.9354 - val_loss: 0.1869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27aQEvli_Y56",
        "outputId": "41a7fa15-01a9-43fc-9a38-2b1bd360bc22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1873\n",
            "Test loss: 0.196896031498909\n",
            "Test accuracy: 0.9330769181251526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yH3MsJMr_rZ4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelpath = './data/model/all/all-{epoch:02d}-{val_loss:.4f}.keras'\n",
        "checkpointer = ModelCheckpoint(filepath = modelpath, verbose=1)"
      ],
      "metadata": {
        "id": "XdJGfswPAn3J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs = 20, batch_size = 500,\n",
        "                    validation_split = 0.25, verbose=0, callbacks=[checkpointer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IDlYRB5CeA4",
        "outputId": "ae9af12b-47c0-4fbd-8750-40882b13d6d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: saving model to ./data/model/all/all-01-0.1849.keras\n",
            "\n",
            "Epoch 2: saving model to ./data/model/all/all-02-0.1838.keras\n",
            "\n",
            "Epoch 3: saving model to ./data/model/all/all-03-0.1825.keras\n",
            "\n",
            "Epoch 4: saving model to ./data/model/all/all-04-0.1812.keras\n",
            "\n",
            "Epoch 5: saving model to ./data/model/all/all-05-0.1797.keras\n",
            "\n",
            "Epoch 6: saving model to ./data/model/all/all-06-0.1780.keras\n",
            "\n",
            "Epoch 7: saving model to ./data/model/all/all-07-0.1767.keras\n",
            "\n",
            "Epoch 8: saving model to ./data/model/all/all-08-0.1755.keras\n",
            "\n",
            "Epoch 9: saving model to ./data/model/all/all-09-0.1743.keras\n",
            "\n",
            "Epoch 10: saving model to ./data/model/all/all-10-0.1730.keras\n",
            "\n",
            "Epoch 11: saving model to ./data/model/all/all-11-0.1682.keras\n",
            "\n",
            "Epoch 12: saving model to ./data/model/all/all-12-0.1645.keras\n",
            "\n",
            "Epoch 13: saving model to ./data/model/all/all-13-0.1612.keras\n",
            "\n",
            "Epoch 14: saving model to ./data/model/all/all-14-0.1579.keras\n",
            "\n",
            "Epoch 15: saving model to ./data/model/all/all-15-0.1544.keras\n",
            "\n",
            "Epoch 16: saving model to ./data/model/all/all-16-0.1513.keras\n",
            "\n",
            "Epoch 17: saving model to ./data/model/all/all-17-0.1501.keras\n",
            "\n",
            "Epoch 18: saving model to ./data/model/all/all-18-0.1472.keras\n",
            "\n",
            "Epoch 19: saving model to ./data/model/all/all-19-0.1451.keras\n",
            "\n",
            "Epoch 20: saving model to ./data/model/all/all-20-0.1443.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# overfit\n",
        "history = model.fit(X_train, y_train, epochs = 2000, batch_size = 500,\n",
        "                    validation_split = 0.25, verbose=0)"
      ],
      "metadata": {
        "id": "GoZWsZyuECQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "ca802f73-d771-40be-f75a-04500b3e1be0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1348998468.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# overfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(X_train, y_train, epochs = 2000, batch_size = 500,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     validation_split = 0.25, verbose=0)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    399\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     )\n\u001b[0;32m--> 401\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    402\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df.head()"
      ],
      "metadata": {
        "id": "Zzfyv0VJESYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_vloss = hist_df['val_loss']\n",
        "y_loss = hist_df['loss']"
      ],
      "metadata": {
        "id": "6Qyr0kNcEXo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='o', c='red', markersize=2, label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='o', c='blue', markersize=2, label='Trainset_loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "3cQf684lExP9",
        "outputId": "5c04301d-b28d-4fcd-a4d1-b029f14430a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VgqgHy02Fn0i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2025.08.13. --2\n",
        "\n",
        "df = pd.read_csv('./data/wine.csv', header=None)\n",
        "\n",
        "X = df.iloc[:,0:12]\n",
        "y = df.iloc[:,12]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim = 12, activation = 'relu'))\n",
        "model.add(Dense(12, activation = 'relu'))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "-UNOYyKzLo47",
        "outputId": "052414b0-41ae-4d37-ede9-caae08303655"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath = './data/model/bestmodel.keras'\n",
        "checkpointer = ModelCheckpoint(filepath = modelpath, verbose=0,\n",
        "                               monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# 성능이 나빠지면 중단되기 때문에 2000번이 다 돌지 않음.\n",
        "history = model.fit(X_train, y_train, epochs = 2000, batch_size = 500,\n",
        "                    validation_split = 0.25, verbose=1,\n",
        "                    callbacks=[early_stopping_callback, checkpointer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSVLuJQMMeiJ",
        "outputId": "1fdd9e4a-c786-4ae2-8e27-7010921e80e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3628 - loss: 1.1086 - val_accuracy: 0.7662 - val_loss: 0.4821\n",
            "Epoch 2/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7828 - loss: 0.4928 - val_accuracy: 0.8292 - val_loss: 0.3891\n",
            "Epoch 3/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8443 - loss: 0.3687 - val_accuracy: 0.8754 - val_loss: 0.3023\n",
            "Epoch 4/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8829 - loss: 0.3044 - val_accuracy: 0.8985 - val_loss: 0.2886\n",
            "Epoch 5/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8878 - loss: 0.2932 - val_accuracy: 0.8977 - val_loss: 0.2512\n",
            "Epoch 6/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8952 - loss: 0.2639 - val_accuracy: 0.9215 - val_loss: 0.2267\n",
            "Epoch 7/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9188 - loss: 0.2361 - val_accuracy: 0.9262 - val_loss: 0.2137\n",
            "Epoch 8/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9208 - loss: 0.2328 - val_accuracy: 0.9254 - val_loss: 0.2035\n",
            "Epoch 9/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9181 - loss: 0.2261 - val_accuracy: 0.9254 - val_loss: 0.1947\n",
            "Epoch 10/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9204 - loss: 0.2246 - val_accuracy: 0.9277 - val_loss: 0.1884\n",
            "Epoch 11/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9250 - loss: 0.2054 - val_accuracy: 0.9315 - val_loss: 0.1842\n",
            "Epoch 12/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9216 - loss: 0.2103 - val_accuracy: 0.9338 - val_loss: 0.1815\n",
            "Epoch 13/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9228 - loss: 0.2057 - val_accuracy: 0.9338 - val_loss: 0.1790\n",
            "Epoch 14/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9211 - loss: 0.2028 - val_accuracy: 0.9354 - val_loss: 0.1767\n",
            "Epoch 15/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9285 - loss: 0.1908 - val_accuracy: 0.9362 - val_loss: 0.1727\n",
            "Epoch 16/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9321 - loss: 0.1939 - val_accuracy: 0.9385 - val_loss: 0.1701\n",
            "Epoch 17/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9297 - loss: 0.1906 - val_accuracy: 0.9385 - val_loss: 0.1692\n",
            "Epoch 18/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9270 - loss: 0.1910 - val_accuracy: 0.9385 - val_loss: 0.1671\n",
            "Epoch 19/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9255 - loss: 0.1971 - val_accuracy: 0.9392 - val_loss: 0.1649\n",
            "Epoch 20/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9281 - loss: 0.1911 - val_accuracy: 0.9385 - val_loss: 0.1631\n",
            "Epoch 21/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9360 - loss: 0.1768 - val_accuracy: 0.9400 - val_loss: 0.1602\n",
            "Epoch 22/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9314 - loss: 0.1899 - val_accuracy: 0.9400 - val_loss: 0.1582\n",
            "Epoch 23/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9334 - loss: 0.1793 - val_accuracy: 0.9423 - val_loss: 0.1552\n",
            "Epoch 24/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9373 - loss: 0.1741 - val_accuracy: 0.9431 - val_loss: 0.1515\n",
            "Epoch 25/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9358 - loss: 0.1750 - val_accuracy: 0.9431 - val_loss: 0.1490\n",
            "Epoch 26/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9342 - loss: 0.1680 - val_accuracy: 0.9423 - val_loss: 0.1467\n",
            "Epoch 27/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9383 - loss: 0.1616 - val_accuracy: 0.9431 - val_loss: 0.1452\n",
            "Epoch 28/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9394 - loss: 0.1568 - val_accuracy: 0.9438 - val_loss: 0.1420\n",
            "Epoch 29/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9390 - loss: 0.1546 - val_accuracy: 0.9446 - val_loss: 0.1403\n",
            "Epoch 30/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9377 - loss: 0.1612 - val_accuracy: 0.9446 - val_loss: 0.1379\n",
            "Epoch 31/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9415 - loss: 0.1520 - val_accuracy: 0.9485 - val_loss: 0.1367\n",
            "Epoch 32/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9378 - loss: 0.1553 - val_accuracy: 0.9500 - val_loss: 0.1359\n",
            "Epoch 33/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9444 - loss: 0.1447 - val_accuracy: 0.9462 - val_loss: 0.1322\n",
            "Epoch 34/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9451 - loss: 0.1461 - val_accuracy: 0.9508 - val_loss: 0.1320\n",
            "Epoch 35/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9429 - loss: 0.1527 - val_accuracy: 0.9485 - val_loss: 0.1285\n",
            "Epoch 36/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9472 - loss: 0.1408 - val_accuracy: 0.9508 - val_loss: 0.1261\n",
            "Epoch 37/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9404 - loss: 0.1507 - val_accuracy: 0.9500 - val_loss: 0.1260\n",
            "Epoch 38/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9395 - loss: 0.1557 - val_accuracy: 0.9492 - val_loss: 0.1231\n",
            "Epoch 39/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9461 - loss: 0.1310 - val_accuracy: 0.9523 - val_loss: 0.1217\n",
            "Epoch 40/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9444 - loss: 0.1454 - val_accuracy: 0.9515 - val_loss: 0.1197\n",
            "Epoch 41/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9482 - loss: 0.1369 - val_accuracy: 0.9531 - val_loss: 0.1176\n",
            "Epoch 42/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9501 - loss: 0.1346 - val_accuracy: 0.9585 - val_loss: 0.1197\n",
            "Epoch 43/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9519 - loss: 0.1283 - val_accuracy: 0.9546 - val_loss: 0.1146\n",
            "Epoch 44/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9569 - loss: 0.1212 - val_accuracy: 0.9546 - val_loss: 0.1131\n",
            "Epoch 45/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9551 - loss: 0.1220 - val_accuracy: 0.9615 - val_loss: 0.1205\n",
            "Epoch 46/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9570 - loss: 0.1308 - val_accuracy: 0.9615 - val_loss: 0.1101\n",
            "Epoch 47/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9580 - loss: 0.1247 - val_accuracy: 0.9608 - val_loss: 0.1084\n",
            "Epoch 48/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9534 - loss: 0.1220 - val_accuracy: 0.9638 - val_loss: 0.1075\n",
            "Epoch 49/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9548 - loss: 0.1235 - val_accuracy: 0.9638 - val_loss: 0.1063\n",
            "Epoch 50/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9584 - loss: 0.1251 - val_accuracy: 0.9600 - val_loss: 0.1050\n",
            "Epoch 51/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9581 - loss: 0.1183 - val_accuracy: 0.9615 - val_loss: 0.1035\n",
            "Epoch 52/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9591 - loss: 0.1203 - val_accuracy: 0.9677 - val_loss: 0.1029\n",
            "Epoch 53/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9580 - loss: 0.1183 - val_accuracy: 0.9669 - val_loss: 0.1012\n",
            "Epoch 54/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9595 - loss: 0.1145 - val_accuracy: 0.9708 - val_loss: 0.1029\n",
            "Epoch 55/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9598 - loss: 0.1192 - val_accuracy: 0.9708 - val_loss: 0.1000\n",
            "Epoch 56/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9620 - loss: 0.1145 - val_accuracy: 0.9700 - val_loss: 0.1026\n",
            "Epoch 57/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9615 - loss: 0.1134 - val_accuracy: 0.9708 - val_loss: 0.1006\n",
            "Epoch 58/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9654 - loss: 0.1094 - val_accuracy: 0.9708 - val_loss: 0.0981\n",
            "Epoch 59/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9622 - loss: 0.1186 - val_accuracy: 0.9723 - val_loss: 0.0950\n",
            "Epoch 60/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9672 - loss: 0.1144 - val_accuracy: 0.9685 - val_loss: 0.0939\n",
            "Epoch 61/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9690 - loss: 0.1055 - val_accuracy: 0.9708 - val_loss: 0.0926\n",
            "Epoch 62/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9650 - loss: 0.0961 - val_accuracy: 0.9723 - val_loss: 0.0918\n",
            "Epoch 63/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: 0.1021 - val_accuracy: 0.9731 - val_loss: 0.0926\n",
            "Epoch 64/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9683 - loss: 0.1059 - val_accuracy: 0.9708 - val_loss: 0.0911\n",
            "Epoch 65/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9695 - loss: 0.1007 - val_accuracy: 0.9746 - val_loss: 0.0905\n",
            "Epoch 66/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9687 - loss: 0.1013 - val_accuracy: 0.9723 - val_loss: 0.0929\n",
            "Epoch 67/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.1051 - val_accuracy: 0.9723 - val_loss: 0.0917\n",
            "Epoch 68/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9691 - loss: 0.1014 - val_accuracy: 0.9738 - val_loss: 0.0888\n",
            "Epoch 69/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9707 - loss: 0.1012 - val_accuracy: 0.9715 - val_loss: 0.0862\n",
            "Epoch 70/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9671 - loss: 0.1065 - val_accuracy: 0.9723 - val_loss: 0.0858\n",
            "Epoch 71/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.1070 - val_accuracy: 0.9708 - val_loss: 0.0862\n",
            "Epoch 72/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9698 - loss: 0.0984 - val_accuracy: 0.9715 - val_loss: 0.0842\n",
            "Epoch 73/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9676 - loss: 0.1082 - val_accuracy: 0.9685 - val_loss: 0.0870\n",
            "Epoch 74/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9666 - loss: 0.1050 - val_accuracy: 0.9738 - val_loss: 0.0829\n",
            "Epoch 75/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9743 - loss: 0.0935 - val_accuracy: 0.9731 - val_loss: 0.0842\n",
            "Epoch 76/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9710 - loss: 0.0981 - val_accuracy: 0.9731 - val_loss: 0.0815\n",
            "Epoch 77/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9732 - loss: 0.0933 - val_accuracy: 0.9746 - val_loss: 0.0806\n",
            "Epoch 78/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9699 - loss: 0.1012 - val_accuracy: 0.9700 - val_loss: 0.0845\n",
            "Epoch 79/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9664 - loss: 0.0950 - val_accuracy: 0.9738 - val_loss: 0.0796\n",
            "Epoch 80/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9721 - loss: 0.0974 - val_accuracy: 0.9738 - val_loss: 0.0788\n",
            "Epoch 81/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9768 - loss: 0.0846 - val_accuracy: 0.9731 - val_loss: 0.0804\n",
            "Epoch 82/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9749 - loss: 0.0849 - val_accuracy: 0.9746 - val_loss: 0.0814\n",
            "Epoch 83/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9732 - loss: 0.0882 - val_accuracy: 0.9731 - val_loss: 0.0775\n",
            "Epoch 84/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9757 - loss: 0.0811 - val_accuracy: 0.9746 - val_loss: 0.0773\n",
            "Epoch 85/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9710 - loss: 0.0949 - val_accuracy: 0.9746 - val_loss: 0.0768\n",
            "Epoch 86/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9769 - loss: 0.0836 - val_accuracy: 0.9746 - val_loss: 0.0759\n",
            "Epoch 87/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0847 - val_accuracy: 0.9746 - val_loss: 0.0759\n",
            "Epoch 88/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9736 - loss: 0.0813 - val_accuracy: 0.9754 - val_loss: 0.0795\n",
            "Epoch 89/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9774 - loss: 0.0781 - val_accuracy: 0.9754 - val_loss: 0.0759\n",
            "Epoch 90/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9751 - loss: 0.0817 - val_accuracy: 0.9762 - val_loss: 0.0747\n",
            "Epoch 91/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9740 - loss: 0.0844 - val_accuracy: 0.9754 - val_loss: 0.0751\n",
            "Epoch 92/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9734 - loss: 0.0860 - val_accuracy: 0.9762 - val_loss: 0.0734\n",
            "Epoch 93/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9763 - loss: 0.0829 - val_accuracy: 0.9762 - val_loss: 0.0742\n",
            "Epoch 94/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9770 - loss: 0.0743 - val_accuracy: 0.9769 - val_loss: 0.0794\n",
            "Epoch 95/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9744 - loss: 0.0832 - val_accuracy: 0.9769 - val_loss: 0.0750\n",
            "Epoch 96/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.0833 - val_accuracy: 0.9769 - val_loss: 0.0797\n",
            "Epoch 97/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9715 - loss: 0.0877 - val_accuracy: 0.9762 - val_loss: 0.0755\n",
            "Epoch 98/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9731 - loss: 0.0838 - val_accuracy: 0.9777 - val_loss: 0.0704\n",
            "Epoch 99/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9764 - loss: 0.0762 - val_accuracy: 0.9769 - val_loss: 0.0697\n",
            "Epoch 100/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9749 - loss: 0.0791 - val_accuracy: 0.9769 - val_loss: 0.0695\n",
            "Epoch 101/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0754 - val_accuracy: 0.9769 - val_loss: 0.0699\n",
            "Epoch 102/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9733 - loss: 0.0849 - val_accuracy: 0.9777 - val_loss: 0.0692\n",
            "Epoch 103/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9751 - loss: 0.0795 - val_accuracy: 0.9785 - val_loss: 0.0692\n",
            "Epoch 104/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9746 - loss: 0.0830 - val_accuracy: 0.9800 - val_loss: 0.0736\n",
            "Epoch 105/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9753 - loss: 0.0818 - val_accuracy: 0.9777 - val_loss: 0.0702\n",
            "Epoch 106/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9782 - loss: 0.0771 - val_accuracy: 0.9800 - val_loss: 0.0717\n",
            "Epoch 107/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9781 - loss: 0.0749 - val_accuracy: 0.9785 - val_loss: 0.0724\n",
            "Epoch 108/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9804 - loss: 0.0723 - val_accuracy: 0.9785 - val_loss: 0.0713\n",
            "Epoch 109/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9808 - loss: 0.0754 - val_accuracy: 0.9785 - val_loss: 0.0712\n",
            "Epoch 110/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9776 - loss: 0.0771 - val_accuracy: 0.9792 - val_loss: 0.0682\n",
            "Epoch 111/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9747 - loss: 0.0785 - val_accuracy: 0.9792 - val_loss: 0.0657\n",
            "Epoch 112/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9757 - loss: 0.0785 - val_accuracy: 0.9769 - val_loss: 0.0663\n",
            "Epoch 113/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9798 - loss: 0.0713 - val_accuracy: 0.9777 - val_loss: 0.0682\n",
            "Epoch 114/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0847 - val_accuracy: 0.9762 - val_loss: 0.0696\n",
            "Epoch 115/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9765 - loss: 0.0790 - val_accuracy: 0.9777 - val_loss: 0.0643\n",
            "Epoch 116/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9758 - loss: 0.0850 - val_accuracy: 0.9769 - val_loss: 0.0644\n",
            "Epoch 117/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0686 - val_accuracy: 0.9815 - val_loss: 0.0666\n",
            "Epoch 118/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9776 - loss: 0.0724 - val_accuracy: 0.9777 - val_loss: 0.0647\n",
            "Epoch 119/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9743 - loss: 0.0783 - val_accuracy: 0.9792 - val_loss: 0.0634\n",
            "Epoch 120/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9793 - loss: 0.0727 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
            "Epoch 121/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9754 - loss: 0.0738 - val_accuracy: 0.9785 - val_loss: 0.0634\n",
            "Epoch 122/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9829 - loss: 0.0667 - val_accuracy: 0.9777 - val_loss: 0.0631\n",
            "Epoch 123/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9777 - loss: 0.0709 - val_accuracy: 0.9777 - val_loss: 0.0629\n",
            "Epoch 124/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9783 - loss: 0.0742 - val_accuracy: 0.9777 - val_loss: 0.0621\n",
            "Epoch 125/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9803 - loss: 0.0725 - val_accuracy: 0.9808 - val_loss: 0.0632\n",
            "Epoch 126/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9803 - loss: 0.0729 - val_accuracy: 0.9792 - val_loss: 0.0629\n",
            "Epoch 127/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9812 - loss: 0.0644 - val_accuracy: 0.9792 - val_loss: 0.0646\n",
            "Epoch 128/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9803 - loss: 0.0722 - val_accuracy: 0.9792 - val_loss: 0.0648\n",
            "Epoch 129/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9825 - loss: 0.0631 - val_accuracy: 0.9785 - val_loss: 0.0669\n",
            "Epoch 130/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9807 - loss: 0.0679 - val_accuracy: 0.9792 - val_loss: 0.0631\n",
            "Epoch 131/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9796 - loss: 0.0673 - val_accuracy: 0.9823 - val_loss: 0.0607\n",
            "Epoch 132/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9801 - loss: 0.0719 - val_accuracy: 0.9800 - val_loss: 0.0626\n",
            "Epoch 133/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9807 - loss: 0.0628 - val_accuracy: 0.9792 - val_loss: 0.0653\n",
            "Epoch 134/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9802 - loss: 0.0671 - val_accuracy: 0.9792 - val_loss: 0.0626\n",
            "Epoch 135/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9803 - loss: 0.0639 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
            "Epoch 136/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9784 - loss: 0.0723 - val_accuracy: 0.9815 - val_loss: 0.0615\n",
            "Epoch 137/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9785 - loss: 0.0757 - val_accuracy: 0.9792 - val_loss: 0.0647\n",
            "Epoch 138/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9809 - loss: 0.0707 - val_accuracy: 0.9800 - val_loss: 0.0598\n",
            "Epoch 139/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9801 - loss: 0.0665 - val_accuracy: 0.9785 - val_loss: 0.0626\n",
            "Epoch 140/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9754 - loss: 0.0768 - val_accuracy: 0.9754 - val_loss: 0.0695\n",
            "Epoch 141/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9761 - loss: 0.0740 - val_accuracy: 0.9777 - val_loss: 0.0669\n",
            "Epoch 142/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9805 - loss: 0.0707 - val_accuracy: 0.9815 - val_loss: 0.0591\n",
            "Epoch 143/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9791 - loss: 0.0699 - val_accuracy: 0.9838 - val_loss: 0.0587\n",
            "Epoch 144/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9817 - loss: 0.0642 - val_accuracy: 0.9808 - val_loss: 0.0595\n",
            "Epoch 145/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9792 - loss: 0.0677 - val_accuracy: 0.9815 - val_loss: 0.0600\n",
            "Epoch 146/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9821 - loss: 0.0671 - val_accuracy: 0.9815 - val_loss: 0.0588\n",
            "Epoch 147/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9817 - loss: 0.0648 - val_accuracy: 0.9800 - val_loss: 0.0593\n",
            "Epoch 148/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9836 - loss: 0.0592 - val_accuracy: 0.9808 - val_loss: 0.0613\n",
            "Epoch 149/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0594 - val_accuracy: 0.9815 - val_loss: 0.0592\n",
            "Epoch 150/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9781 - loss: 0.0754 - val_accuracy: 0.9815 - val_loss: 0.0585\n",
            "Epoch 151/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.0647 - val_accuracy: 0.9823 - val_loss: 0.0584\n",
            "Epoch 152/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9799 - loss: 0.0637 - val_accuracy: 0.9815 - val_loss: 0.0578\n",
            "Epoch 153/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9834 - loss: 0.0619 - val_accuracy: 0.9815 - val_loss: 0.0581\n",
            "Epoch 154/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9830 - loss: 0.0595 - val_accuracy: 0.9815 - val_loss: 0.0583\n",
            "Epoch 155/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0642 - val_accuracy: 0.9823 - val_loss: 0.0580\n",
            "Epoch 156/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0626 - val_accuracy: 0.9815 - val_loss: 0.0586\n",
            "Epoch 157/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9827 - loss: 0.0599 - val_accuracy: 0.9815 - val_loss: 0.0588\n",
            "Epoch 158/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.0691 - val_accuracy: 0.9823 - val_loss: 0.0599\n",
            "Epoch 159/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9847 - loss: 0.0580 - val_accuracy: 0.9831 - val_loss: 0.0568\n",
            "Epoch 160/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9808 - loss: 0.0595 - val_accuracy: 0.9838 - val_loss: 0.0570\n",
            "Epoch 161/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0594 - val_accuracy: 0.9838 - val_loss: 0.0572\n",
            "Epoch 162/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9817 - loss: 0.0619 - val_accuracy: 0.9823 - val_loss: 0.0569\n",
            "Epoch 163/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9776 - loss: 0.0703 - val_accuracy: 0.9823 - val_loss: 0.0598\n",
            "Epoch 164/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9811 - loss: 0.0664 - val_accuracy: 0.9838 - val_loss: 0.0570\n",
            "Epoch 165/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9821 - loss: 0.0594 - val_accuracy: 0.9823 - val_loss: 0.0566\n",
            "Epoch 166/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9811 - loss: 0.0662 - val_accuracy: 0.9815 - val_loss: 0.0568\n",
            "Epoch 167/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9806 - loss: 0.0646 - val_accuracy: 0.9823 - val_loss: 0.0562\n",
            "Epoch 168/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.0618 - val_accuracy: 0.9838 - val_loss: 0.0561\n",
            "Epoch 169/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9811 - loss: 0.0716 - val_accuracy: 0.9831 - val_loss: 0.0561\n",
            "Epoch 170/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9834 - loss: 0.0551 - val_accuracy: 0.9815 - val_loss: 0.0620\n",
            "Epoch 171/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9839 - loss: 0.0629 - val_accuracy: 0.9823 - val_loss: 0.0573\n",
            "Epoch 172/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9829 - loss: 0.0621 - val_accuracy: 0.9838 - val_loss: 0.0588\n",
            "Epoch 173/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9809 - loss: 0.0636 - val_accuracy: 0.9823 - val_loss: 0.0553\n",
            "Epoch 174/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9823 - loss: 0.0617 - val_accuracy: 0.9831 - val_loss: 0.0547\n",
            "Epoch 175/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0561 - val_accuracy: 0.9823 - val_loss: 0.0553\n",
            "Epoch 176/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9822 - loss: 0.0599 - val_accuracy: 0.9823 - val_loss: 0.0567\n",
            "Epoch 177/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9834 - loss: 0.0571 - val_accuracy: 0.9823 - val_loss: 0.0550\n",
            "Epoch 178/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0642 - val_accuracy: 0.9846 - val_loss: 0.0574\n",
            "Epoch 179/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9850 - loss: 0.0642 - val_accuracy: 0.9838 - val_loss: 0.0550\n",
            "Epoch 180/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9841 - loss: 0.0561 - val_accuracy: 0.9831 - val_loss: 0.0556\n",
            "Epoch 181/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9829 - loss: 0.0598 - val_accuracy: 0.9831 - val_loss: 0.0548\n",
            "Epoch 182/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9872 - loss: 0.0520 - val_accuracy: 0.9846 - val_loss: 0.0550\n",
            "Epoch 183/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9852 - loss: 0.0568 - val_accuracy: 0.9831 - val_loss: 0.0552\n",
            "Epoch 184/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9825 - loss: 0.0566 - val_accuracy: 0.9831 - val_loss: 0.0552\n",
            "Epoch 185/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9816 - loss: 0.0557 - val_accuracy: 0.9823 - val_loss: 0.0544\n",
            "Epoch 186/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9825 - loss: 0.0576 - val_accuracy: 0.9831 - val_loss: 0.0567\n",
            "Epoch 187/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9835 - loss: 0.0590 - val_accuracy: 0.9831 - val_loss: 0.0545\n",
            "Epoch 188/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9836 - loss: 0.0584 - val_accuracy: 0.9838 - val_loss: 0.0559\n",
            "Epoch 189/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9849 - loss: 0.0511 - val_accuracy: 0.9831 - val_loss: 0.0579\n",
            "Epoch 190/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9809 - loss: 0.0568 - val_accuracy: 0.9831 - val_loss: 0.0604\n",
            "Epoch 191/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9826 - loss: 0.0652 - val_accuracy: 0.9831 - val_loss: 0.0570\n",
            "Epoch 192/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9840 - loss: 0.0596 - val_accuracy: 0.9815 - val_loss: 0.0542\n",
            "Epoch 193/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9834 - loss: 0.0545 - val_accuracy: 0.9823 - val_loss: 0.0539\n",
            "Epoch 194/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9812 - loss: 0.0615 - val_accuracy: 0.9831 - val_loss: 0.0548\n",
            "Epoch 195/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9822 - loss: 0.0630 - val_accuracy: 0.9815 - val_loss: 0.0539\n",
            "Epoch 196/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9808 - loss: 0.0656 - val_accuracy: 0.9838 - val_loss: 0.0570\n",
            "Epoch 197/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0618 - val_accuracy: 0.9823 - val_loss: 0.0540\n",
            "Epoch 198/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0624 - val_accuracy: 0.9838 - val_loss: 0.0545\n",
            "Epoch 199/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9812 - loss: 0.0577 - val_accuracy: 0.9846 - val_loss: 0.0537\n",
            "Epoch 200/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0538 - val_accuracy: 0.9838 - val_loss: 0.0543\n",
            "Epoch 201/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0606 - val_accuracy: 0.9823 - val_loss: 0.0538\n",
            "Epoch 202/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9831 - loss: 0.0589 - val_accuracy: 0.9831 - val_loss: 0.0552\n",
            "Epoch 203/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9836 - loss: 0.0625 - val_accuracy: 0.9831 - val_loss: 0.0538\n",
            "Epoch 204/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9816 - loss: 0.0689 - val_accuracy: 0.9838 - val_loss: 0.0579\n",
            "Epoch 205/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9820 - loss: 0.0567 - val_accuracy: 0.9831 - val_loss: 0.0544\n",
            "Epoch 206/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9831 - loss: 0.0529 - val_accuracy: 0.9831 - val_loss: 0.0535\n",
            "Epoch 207/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0507 - val_accuracy: 0.9823 - val_loss: 0.0572\n",
            "Epoch 208/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9837 - loss: 0.0603 - val_accuracy: 0.9831 - val_loss: 0.0553\n",
            "Epoch 209/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0524 - val_accuracy: 0.9823 - val_loss: 0.0577\n",
            "Epoch 210/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9825 - loss: 0.0544 - val_accuracy: 0.9831 - val_loss: 0.0572\n",
            "Epoch 211/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9816 - loss: 0.0540 - val_accuracy: 0.9831 - val_loss: 0.0543\n",
            "Epoch 212/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9843 - loss: 0.0535 - val_accuracy: 0.9823 - val_loss: 0.0532\n",
            "Epoch 213/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9841 - loss: 0.0564 - val_accuracy: 0.9831 - val_loss: 0.0571\n",
            "Epoch 214/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9831 - loss: 0.0566 - val_accuracy: 0.9838 - val_loss: 0.0579\n",
            "Epoch 215/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9824 - loss: 0.0567 - val_accuracy: 0.9831 - val_loss: 0.0544\n",
            "Epoch 216/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.0512 - val_accuracy: 0.9831 - val_loss: 0.0569\n",
            "Epoch 217/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9840 - loss: 0.0563 - val_accuracy: 0.9831 - val_loss: 0.0573\n",
            "Epoch 218/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0539 - val_accuracy: 0.9831 - val_loss: 0.0557\n",
            "Epoch 219/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9856 - loss: 0.0599 - val_accuracy: 0.9846 - val_loss: 0.0530\n",
            "Epoch 220/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9809 - loss: 0.0654 - val_accuracy: 0.9838 - val_loss: 0.0579\n",
            "Epoch 221/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9807 - loss: 0.0590 - val_accuracy: 0.9823 - val_loss: 0.0525\n",
            "Epoch 222/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9843 - loss: 0.0631 - val_accuracy: 0.9846 - val_loss: 0.0569\n",
            "Epoch 223/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0643 - val_accuracy: 0.9846 - val_loss: 0.0568\n",
            "Epoch 224/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9802 - loss: 0.0729 - val_accuracy: 0.9815 - val_loss: 0.0599\n",
            "Epoch 225/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9779 - loss: 0.0776 - val_accuracy: 0.9815 - val_loss: 0.0527\n",
            "Epoch 226/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9817 - loss: 0.0676 - val_accuracy: 0.9831 - val_loss: 0.0572\n",
            "Epoch 227/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9849 - loss: 0.0535 - val_accuracy: 0.9808 - val_loss: 0.0636\n",
            "Epoch 228/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9835 - loss: 0.0555 - val_accuracy: 0.9823 - val_loss: 0.0552\n",
            "Epoch 229/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9852 - loss: 0.0531 - val_accuracy: 0.9846 - val_loss: 0.0518\n",
            "Epoch 230/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9851 - loss: 0.0469 - val_accuracy: 0.9831 - val_loss: 0.0574\n",
            "Epoch 231/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9841 - loss: 0.0576 - val_accuracy: 0.9838 - val_loss: 0.0529\n",
            "Epoch 232/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0571 - val_accuracy: 0.9831 - val_loss: 0.0523\n",
            "Epoch 233/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0540 - val_accuracy: 0.9831 - val_loss: 0.0553\n",
            "Epoch 234/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9862 - loss: 0.0546 - val_accuracy: 0.9823 - val_loss: 0.0523\n",
            "Epoch 235/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0582 - val_accuracy: 0.9838 - val_loss: 0.0546\n",
            "Epoch 236/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9822 - loss: 0.0612 - val_accuracy: 0.9838 - val_loss: 0.0541\n",
            "Epoch 237/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0546 - val_accuracy: 0.9838 - val_loss: 0.0531\n",
            "Epoch 238/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9826 - loss: 0.0543 - val_accuracy: 0.9831 - val_loss: 0.0516\n",
            "Epoch 239/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0533 - val_accuracy: 0.9831 - val_loss: 0.0544\n",
            "Epoch 240/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9851 - loss: 0.0544 - val_accuracy: 0.9831 - val_loss: 0.0533\n",
            "Epoch 241/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9850 - loss: 0.0508 - val_accuracy: 0.9831 - val_loss: 0.0549\n",
            "Epoch 242/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 0.0470 - val_accuracy: 0.9823 - val_loss: 0.0524\n",
            "Epoch 243/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9877 - loss: 0.0465 - val_accuracy: 0.9831 - val_loss: 0.0535\n",
            "Epoch 244/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9858 - loss: 0.0491 - val_accuracy: 0.9823 - val_loss: 0.0571\n",
            "Epoch 245/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9852 - loss: 0.0594 - val_accuracy: 0.9838 - val_loss: 0.0557\n",
            "Epoch 246/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9856 - loss: 0.0554 - val_accuracy: 0.9815 - val_loss: 0.0577\n",
            "Epoch 247/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0549 - val_accuracy: 0.9823 - val_loss: 0.0519\n",
            "Epoch 248/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9826 - loss: 0.0536 - val_accuracy: 0.9823 - val_loss: 0.0518\n",
            "Epoch 249/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9846 - loss: 0.0562 - val_accuracy: 0.9823 - val_loss: 0.0524\n",
            "Epoch 250/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9842 - loss: 0.0486 - val_accuracy: 0.9815 - val_loss: 0.0564\n",
            "Epoch 251/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9795 - loss: 0.0642 - val_accuracy: 0.9808 - val_loss: 0.0657\n",
            "Epoch 252/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.0623 - val_accuracy: 0.9800 - val_loss: 0.0685\n",
            "Epoch 253/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9844 - loss: 0.0607 - val_accuracy: 0.9815 - val_loss: 0.0553\n",
            "Epoch 254/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9874 - loss: 0.0511 - val_accuracy: 0.9831 - val_loss: 0.0540\n",
            "Epoch 255/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9841 - loss: 0.0552 - val_accuracy: 0.9823 - val_loss: 0.0522\n",
            "Epoch 256/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9863 - loss: 0.0487 - val_accuracy: 0.9831 - val_loss: 0.0540\n",
            "Epoch 257/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9860 - loss: 0.0573 - val_accuracy: 0.9831 - val_loss: 0.0516\n",
            "Epoch 258/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9867 - loss: 0.0488 - val_accuracy: 0.9838 - val_loss: 0.0513\n",
            "Epoch 259/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9867 - loss: 0.0542 - val_accuracy: 0.9838 - val_loss: 0.0527\n",
            "Epoch 260/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9854 - loss: 0.0509 - val_accuracy: 0.9846 - val_loss: 0.0513\n",
            "Epoch 261/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9837 - loss: 0.0575 - val_accuracy: 0.9808 - val_loss: 0.0662\n",
            "Epoch 262/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9820 - loss: 0.0636 - val_accuracy: 0.9815 - val_loss: 0.0554\n",
            "Epoch 263/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9831 - loss: 0.0580 - val_accuracy: 0.9823 - val_loss: 0.0525\n",
            "Epoch 264/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0508 - val_accuracy: 0.9831 - val_loss: 0.0537\n",
            "Epoch 265/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9848 - loss: 0.0503 - val_accuracy: 0.9838 - val_loss: 0.0510\n",
            "Epoch 266/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9845 - loss: 0.0529 - val_accuracy: 0.9823 - val_loss: 0.0521\n",
            "Epoch 267/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9860 - loss: 0.0505 - val_accuracy: 0.9838 - val_loss: 0.0512\n",
            "Epoch 268/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0455 - val_accuracy: 0.9808 - val_loss: 0.0572\n",
            "Epoch 269/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9829 - loss: 0.0592 - val_accuracy: 0.9831 - val_loss: 0.0528\n",
            "Epoch 270/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.0503 - val_accuracy: 0.9838 - val_loss: 0.0511\n",
            "Epoch 271/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9860 - loss: 0.0557 - val_accuracy: 0.9823 - val_loss: 0.0544\n",
            "Epoch 272/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9838 - loss: 0.0520 - val_accuracy: 0.9831 - val_loss: 0.0529\n",
            "Epoch 273/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9843 - loss: 0.0533 - val_accuracy: 0.9808 - val_loss: 0.0636\n",
            "Epoch 274/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0560 - val_accuracy: 0.9808 - val_loss: 0.0589\n",
            "Epoch 275/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9835 - loss: 0.0557 - val_accuracy: 0.9823 - val_loss: 0.0546\n",
            "Epoch 276/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9879 - loss: 0.0445 - val_accuracy: 0.9808 - val_loss: 0.0556\n",
            "Epoch 277/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0505 - val_accuracy: 0.9815 - val_loss: 0.0563\n",
            "Epoch 278/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0497 - val_accuracy: 0.9823 - val_loss: 0.0558\n",
            "Epoch 279/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9830 - loss: 0.0529 - val_accuracy: 0.9823 - val_loss: 0.0509\n",
            "Epoch 280/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0469 - val_accuracy: 0.9831 - val_loss: 0.0513\n",
            "Epoch 281/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0471 - val_accuracy: 0.9831 - val_loss: 0.0530\n",
            "Epoch 282/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9872 - loss: 0.0507 - val_accuracy: 0.9823 - val_loss: 0.0540\n",
            "Epoch 283/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9855 - loss: 0.0516 - val_accuracy: 0.9846 - val_loss: 0.0509\n",
            "Epoch 284/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9824 - loss: 0.0518 - val_accuracy: 0.9831 - val_loss: 0.0530\n",
            "Epoch 285/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9867 - loss: 0.0440 - val_accuracy: 0.9808 - val_loss: 0.0597\n",
            "Epoch 286/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0532 - val_accuracy: 0.9800 - val_loss: 0.0608\n",
            "Epoch 287/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9868 - loss: 0.0549 - val_accuracy: 0.9808 - val_loss: 0.0570\n",
            "Epoch 288/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9836 - loss: 0.0568 - val_accuracy: 0.9823 - val_loss: 0.0511\n",
            "Epoch 289/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9848 - loss: 0.0554 - val_accuracy: 0.9823 - val_loss: 0.0518\n",
            "Epoch 290/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9857 - loss: 0.0504 - val_accuracy: 0.9846 - val_loss: 0.0510\n",
            "Epoch 291/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9868 - loss: 0.0558 - val_accuracy: 0.9831 - val_loss: 0.0509\n",
            "Epoch 292/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9866 - loss: 0.0476 - val_accuracy: 0.9846 - val_loss: 0.0510\n",
            "Epoch 293/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9853 - loss: 0.0483 - val_accuracy: 0.9808 - val_loss: 0.0564\n",
            "Epoch 294/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.0583 - val_accuracy: 0.9823 - val_loss: 0.0521\n",
            "Epoch 295/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9874 - loss: 0.0432 - val_accuracy: 0.9831 - val_loss: 0.0530\n",
            "Epoch 296/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9866 - loss: 0.0502 - val_accuracy: 0.9831 - val_loss: 0.0520\n",
            "Epoch 297/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.0554 - val_accuracy: 0.9831 - val_loss: 0.0527\n",
            "Epoch 298/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9854 - loss: 0.0494 - val_accuracy: 0.9823 - val_loss: 0.0516\n",
            "Epoch 299/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9847 - loss: 0.0528 - val_accuracy: 0.9838 - val_loss: 0.0505\n",
            "Epoch 300/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9884 - loss: 0.0463 - val_accuracy: 0.9823 - val_loss: 0.0508\n",
            "Epoch 301/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9854 - loss: 0.0551 - val_accuracy: 0.9823 - val_loss: 0.0516\n",
            "Epoch 302/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9849 - loss: 0.0535 - val_accuracy: 0.9838 - val_loss: 0.0506\n",
            "Epoch 303/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9857 - loss: 0.0522 - val_accuracy: 0.9815 - val_loss: 0.0552\n",
            "Epoch 304/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9839 - loss: 0.0514 - val_accuracy: 0.9831 - val_loss: 0.0529\n",
            "Epoch 305/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9854 - loss: 0.0503 - val_accuracy: 0.9815 - val_loss: 0.0601\n",
            "Epoch 306/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0585 - val_accuracy: 0.9823 - val_loss: 0.0511\n",
            "Epoch 307/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9861 - loss: 0.0559 - val_accuracy: 0.9831 - val_loss: 0.0516\n",
            "Epoch 308/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9860 - loss: 0.0534 - val_accuracy: 0.9823 - val_loss: 0.0525\n",
            "Epoch 309/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9887 - loss: 0.0487 - val_accuracy: 0.9823 - val_loss: 0.0523\n",
            "Epoch 310/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9862 - loss: 0.0536 - val_accuracy: 0.9846 - val_loss: 0.0526\n",
            "Epoch 311/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9847 - loss: 0.0492 - val_accuracy: 0.9846 - val_loss: 0.0526\n",
            "Epoch 312/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9845 - loss: 0.0497 - val_accuracy: 0.9838 - val_loss: 0.0504\n",
            "Epoch 313/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9845 - loss: 0.0493 - val_accuracy: 0.9831 - val_loss: 0.0508\n",
            "Epoch 314/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0523 - val_accuracy: 0.9831 - val_loss: 0.0534\n",
            "Epoch 315/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9883 - loss: 0.0517 - val_accuracy: 0.9815 - val_loss: 0.0558\n",
            "Epoch 316/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9874 - loss: 0.0509 - val_accuracy: 0.9815 - val_loss: 0.0576\n",
            "Epoch 317/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9835 - loss: 0.0561 - val_accuracy: 0.9831 - val_loss: 0.0507\n",
            "Epoch 318/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9881 - loss: 0.0441 - val_accuracy: 0.9831 - val_loss: 0.0509\n",
            "Epoch 319/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9864 - loss: 0.0469 - val_accuracy: 0.9831 - val_loss: 0.0528\n",
            "Epoch 320/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9847 - loss: 0.0575 - val_accuracy: 0.9823 - val_loss: 0.0510\n",
            "Epoch 321/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9873 - loss: 0.0469 - val_accuracy: 0.9823 - val_loss: 0.0511\n",
            "Epoch 322/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9858 - loss: 0.0466 - val_accuracy: 0.9823 - val_loss: 0.0511\n",
            "Epoch 323/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9872 - loss: 0.0486 - val_accuracy: 0.9808 - val_loss: 0.0600\n",
            "Epoch 324/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9851 - loss: 0.0544 - val_accuracy: 0.9815 - val_loss: 0.0582\n",
            "Epoch 325/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9861 - loss: 0.0509 - val_accuracy: 0.9831 - val_loss: 0.0525\n",
            "Epoch 326/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9851 - loss: 0.0497 - val_accuracy: 0.9823 - val_loss: 0.0514\n",
            "Epoch 327/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9860 - loss: 0.0458 - val_accuracy: 0.9815 - val_loss: 0.0520\n",
            "Epoch 328/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9861 - loss: 0.0507 - val_accuracy: 0.9823 - val_loss: 0.0514\n",
            "Epoch 329/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9847 - loss: 0.0545 - val_accuracy: 0.9823 - val_loss: 0.0509\n",
            "Epoch 330/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0543 - val_accuracy: 0.9823 - val_loss: 0.0512\n",
            "Epoch 331/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9848 - loss: 0.0537 - val_accuracy: 0.9831 - val_loss: 0.0517\n",
            "Epoch 332/2000\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9880 - loss: 0.0430 - val_accuracy: 0.9815 - val_loss: 0.0540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 모델~ 엄청난 정확도~~\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQEu28NaOEVw",
        "outputId": "f254d78a-7b9e-4b3f-db74-b4c739ed1a43"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0357\n",
            "Test loss: 0.049272794276475906\n",
            "Test accuracy: 0.9884615540504456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2025.08.13. --3\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding\n",
        "from numpy import array"
      ],
      "metadata": {
        "id": "_r9IrZZKR1jS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '해보지 않으면 해낼 수 없다'\n",
        "\n",
        "result = text_to_word_sequence(text)\n",
        "print(\"\\n원문:\\n\", text)\n",
        "print(\"\\n토큰화:\\n\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQhd-la5DKSn",
        "outputId": "9817f0f9-9004-4579-9ab6-e3087b66009b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "원문:\n",
            " 해보지 않으면 해낼 수 없다\n",
            "\n",
            "토큰화:\n",
            " ['해보지', '않으면', '해낼', '수', '없다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    '먼저 텍스트의 각 단어를 나누어 토큰화를 합니다.',\n",
        "    '텍스트의 단어로 토큰화해야 딥러닝에서 인식됩니다.',\n",
        "    '토큰화한 결과는 딥러닝에서 사용할 수 있습니다.'\n",
        "]\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "\n",
        "print('\\n단어 카운트:\\n', token.word_counts)\n",
        "print('\\n문장 카운트:\\n', token.document_count)\n",
        "print('\\n각 단어에 매겨진 인덱스 값:\\n', token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8rB_yEaDjAx",
        "outputId": "c8484fac-b910-43ba-b546-a203cea26cf4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "단어 카운트:\n",
            " OrderedDict([('먼저', 1), ('텍스트의', 2), ('각', 1), ('단어를', 1), ('나누어', 1), ('토큰화를', 1), ('합니다', 1), ('단어로', 1), ('토큰화해야', 1), ('딥러닝에서', 2), ('인식됩니다', 1), ('토큰화한', 1), ('결과는', 1), ('사용할', 1), ('수', 1), ('있습니다', 1)])\n",
            "\n",
            "문장 카운트:\n",
            " 3\n",
            "\n",
            "각 단어에 매겨진 인덱스 값:\n",
            " {'텍스트의': 1, '딥러닝에서': 2, '먼저': 3, '각': 4, '단어를': 5, '나누어': 6, '토큰화를': 7, '합니다': 8, '단어로': 9, '토큰화해야': 10, '인식됩니다': 11, '토큰화한': 12, '결과는': 13, '사용할': 14, '수': 15, '있습니다': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## one-hot incoding\n",
        "\n",
        "text = '오랫동안 꿈꾸는 이는 그 꿈을 닮아간다'\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts([text])\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SpaxD4EEaoK",
        "outputId": "e248607a-73f4-4eab-b0ca-42986b959375"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'오랫동안': 1, '꿈꾸는': 2, '이는': 3, '그': 4, '꿈을': 5, '닮아간다': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences([text])\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNHsJNfgF245",
        "outputId": "706d322b-5b9b-4c80-aa5e-13196ce4d7e9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 5, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_size = len(token.word_index) + 1\n",
        "x = to_categorical(x, num_classes = word_size)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JpJV9GkGGrh",
        "outputId": "0141c1c2-4083-41c3-c86e-199105b7e631"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터\n",
        "docs = [\n",
        "    '너무 재밌네요', '최고예요', '참 잘 만든 영화예요', '추천하고 싶은 영화입니다', '한번 더 보고싶네요',\n",
        "    '글쎄요', '별로예요', '생각보다 지루하네요', '연기가 어색해요', '재미없어요'\n",
        "]\n",
        "\n",
        "# 정답데이터 // 긍정은 1, 부정은 0\n",
        "classes = array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "print(token.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU-0tttHGvRl",
        "outputId": "5b3c016b-2e89-4a7f-c810-b5f12cf6561d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'너무': 1, '재밌네요': 2, '최고예요': 3, '참': 4, '잘': 5, '만든': 6, '영화예요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한번': 11, '더': 12, '보고싶네요': 13, '글쎄요': 14, '별로예요': 15, '생각보다': 16, '지루하네요': 17, '연기가': 18, '어색해요': 19, '재미없어요': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = token.texts_to_sequences(docs)\n",
        "print('\\n리뷰 텍스트, 토큰화 결과: \\n', x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-_euO-EIhHk",
        "outputId": "8b83ff4e-618e-4fc0-f8ef-6dcf4cc3138d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "리뷰 텍스트, 토큰화 결과: \n",
            " [[1, 2], [3], [4, 5, 6, 7], [8, 9, 10], [11, 12, 13], [14], [15], [16, 17], [18, 19], [20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x = pad_sequences(x, 4)\n",
        "print('\\n패딩결과: \\n', padded_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4uk2MgwIsbR",
        "outputId": "0913cd63-2344-4128-d7dc-3ff42e50e2ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "패딩결과: \n",
            " [[ 0  0  1  2]\n",
            " [ 0  0  0  3]\n",
            " [ 4  5  6  7]\n",
            " [ 0  8  9 10]\n",
            " [ 0 11 12 13]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 15]\n",
            " [ 0  0 16 17]\n",
            " [ 0  0 18 19]\n",
            " [ 0  0  0 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2025.08.14. --1\n",
        "\n",
        "word_size = len(token.word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 8))\n",
        "model.build((None, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "A_X64sCA5IIn",
        "outputId": "5f5df187-3b54-4078-8224-1ed54c84b786"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │           \u001b[38;5;34m168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201\u001b[0m (804.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> (804.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201\u001b[0m (804.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> (804.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded_x, classes, epochs=20)\n",
        "print('\\n Accuracy: %.4f' % (model.evaluate(padded_x, classes)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiVPdHIK93ks",
        "outputId": "d892e7f0-a576-4df4-8445-8f400088b862"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.9000 - loss: 0.6806\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9000 - loss: 0.6786\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.9000 - loss: 0.6766\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9000 - loss: 0.6746\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9000 - loss: 0.6726\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9000 - loss: 0.6706\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9000 - loss: 0.6686\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.9000 - loss: 0.6666\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9000 - loss: 0.6646\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9000 - loss: 0.6626\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9000 - loss: 0.6606\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9000 - loss: 0.6586\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9000 - loss: 0.6566\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9000 - loss: 0.6545\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9000 - loss: 0.6525\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9000 - loss: 0.6504\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9000 - loss: 0.6484\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.6463\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6442\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6421\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.6400\n",
            "\n",
            " Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x[7].shape\n",
        "padded_x[7].reshape(1, -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb3tzPWXAJir",
        "outputId": "b5638948-845e-4e91-b317-c829da103396"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = padded_x[7].reshape(1, -1)\n",
        "prediction = model.predict(sample_input)\n",
        "print('예측된 확률:', prediction[0][0])\n",
        "print('예측된 클래스:', 1 if prediction[0][0] >= 0.5 else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE30BZuF-s22",
        "outputId": "a10eb667-6b12-4f76-8660-584add4cb335"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "예측된 확률: 0.45626575\n",
            "예측된 클래스: 0\n"
          ]
        }
      ]
    }
  ]
}